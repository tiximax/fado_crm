# Storage drivers abstraction for FADO CRM import os from typing import Optional, Tuple class StorageDriver: def save_bytes(self, category: str, filename: str, data: bytes) -> str: raise NotImplementedError def delete(self, category: str, filename: str) -> bool: raise NotImplementedError def public_url(self, category: str, filename: str) -> str: raise NotImplementedError def exists(self, category: str, filename: str) -> bool: raise NotImplementedError def list(self, category: str, prefix: Optional[str] = None, limit: int = 100): """List files within a category. Returns list of dicts with keys: filename, url, size, last_modified""" raise NotImplementedError class LocalStorageDriver(StorageDriver): def __init__(self, base_dir: str = 'uploads'): from pathlib import Path self.base = Path(base_dir) self.base.mkdir(parents=True, exist_ok=True) def _path(self, category: str, filename: str): from pathlib import Path p = self.base / category p.mkdir(parents=True, exist_ok=True) return p / filename def save_bytes(self, category: str, filename: str, data: bytes) -> str: path = self._path(category, filename) with open(path, 'wb') as f: f.write(data) return f"/uploads/{category}/{filename}" def delete(self, category: str, filename: str) -> bool: try: path = self._path(category, filename) if path.exists(): path.unlink() return True except Exception: return False def exists(self, category: str, filename: str) -> bool: try: path = self._path(category, filename) return path.exists() except Exception: return False def public_url(self, category: str, filename: str) -> str: return f"/uploads/{category}/{filename}" def list(self, category: str, prefix: Optional[str] = None, limit: int = 100): from pathlib import Path dir_path = self.base / category results = [] if not dir_path.exists(): return results files = [p for p in dir_path.iterdir() if p.is_file()] # filter by prefix if prefix: files = [p for p in files if p.name.startswith(prefix)] # sort by modified time desc files.sort(key=lambda p: p.stat().st_mtime, reverse=True) for p in files[:max(0, limit)]: try: stat = p.stat() results.append({ "filename": p.name, "url": self.public_url(category, p.name), "size": stat.st_size, "last_modified": stat.st_mtime, }) except Exception: continue return results class S3StorageDriver(StorageDriver): def __init__(self): import boto3 self.region = os.getenv('S3_REGION') self.endpoint = os.getenv('S3_ENDPOINT') self.bucket = os.getenv('S3_BUCKET', 'fado-crm') self.session = boto3.session.Session( aws_access_key_id=os.getenv('S3_ACCESS_KEY'), aws_secret_access_key=os.getenv('S3_SECRET_KEY'), region_name=self.region, ) self.client = self.session.client('s3', endpoint_url=self.endpoint, config=None) self.use_path_style = os.getenv('S3_USE_PATH_STYLE', 'true').lower() == 'true' def _key(self, category: str, filename: str) -> str: return f"{category}/{filename}" def save_bytes(self, category: str, filename: str, data: bytes) -> str: self.client.put_object(Bucket=self.bucket, Key=self._key(category, filename), Body=data) return self.public_url(category, filename) def delete(self, category: str, filename: str) -> bool: try: self.client.delete_object(Bucket=self.bucket, Key=self._key(category, filename)) return True except Exception: return False def exists(self, category: str, filename: str) -> bool: try: self.client.head_object(Bucket=self.bucket, Key=self._key(category, filename)) return True except Exception: return False def public_url(self, category: str, filename: str) -> str: key = self._key(category, filename) if self.endpoint: # Construct URL for custom endpoint if self.use_path_style: return f"{self._ensure_scheme(self.endpoint)}/{self.bucket}/{key}" else: host = self._ensure_scheme(self.endpoint) return f"{host}/{key}" # Default AWS URL return f"https://{self.bucket}.s3.{self.region}.amazonaws.com/{key}" def list(self, category: str, prefix: Optional[str] = None, limit: int = 100): full_prefix = f"{category}/" if prefix: full_prefix += prefix try: params = {"Bucket": self.bucket, "Prefix": full_prefix} results = [] token = None while True: if token: params["ContinuationToken"] = token resp = self.client.list_objects_v2(**params) contents = resp.get("Contents", []) for obj in contents: key = obj["Key"] # Only include files under category (skip directories) if not key.endswith('/'): filename = key.split('/', 1)[1] if '/' in key else key results.append({ "filename": filename, "url": self.public_url(category, filename), "size": obj.get("Size"), "last_modified": obj.get("LastModified").timestamp() if obj.get("LastModified") else None, }) if len(results) >= limit: return results if resp.get("IsTruncated"): token = resp.get("NextContinuationToken") else: break return results except Exception: return [] @staticmethod def _ensure_scheme(endpoint: str) -> str: if endpoint.startswith('http://') or endpoint.startswith('https://'): return endpoint.rstrip('/') # default to https for safety return f"https://{endpoint.strip('/')}" class MinioStorageDriver(StorageDriver): def __init__(self): from minio import Minio endpoint = os.getenv('MINIO_ENDPOINT', 'localhost:9000') secure = os.getenv('MINIO_SECURE', 'false').lower() == 'true' access_key = os.getenv('MINIO_ACCESS_KEY') secret_key = os.getenv('MINIO_SECRET_KEY') self.bucket = os.getenv('MINIO_BUCKET', 'fado-crm') self.client = Minio(endpoint, access_key=access_key, secret_key=secret_key, secure=secure) # Ensure bucket exists if not self.client.bucket_exists(self.bucket): self.client.make_bucket(self.bucket) self.secure = secure self.endpoint = endpoint def _key(self, category: str, filename: str) -> str: return f"{category}/{filename}" def save_bytes(self, category: str, filename: str, data: bytes) -> str: from io import BytesIO bio = BytesIO(data) length = len(data) self.client.put_object(self.bucket, self._key(category, filename), bio, length) return self.public_url(category, filename) def delete(self, category: str, filename: str) -> bool: try: self.client.remove_object(self.bucket, self._key(category, filename)) return True except Exception: return False def exists(self, category: str, filename: str) -> bool: try: self.client.stat_object(self.bucket, self._key(category, filename)) return True except Exception: return False def public_url(self, category: str, filename: str) -> str: scheme = 'https' if self.secure else 'http' return f"{scheme}://{self.endpoint}/{self.bucket}/{self._key(category, filename)}" def list(self, category: str, prefix: Optional[str] = None, limit: int = 100): from minio import S3Error results = [] list_prefix = f"{category}/" if prefix: list_prefix += prefix try: for obj in self.client.list_objects(self.bucket, prefix=list_prefix, recursive=True): key = obj.object_name if key.endswith('/'): continue filename = key.split('/', 1)[1] if '/' in key else key results.append({ "filename": filename, "url": self.public_url(category, filename), "size": obj.size, "last_modified": obj.last_modified.timestamp() if getattr(obj, 'last_modified', None) else None, }) if len(results) >= limit: break return results except Exception: return [] def get_storage_driver(): driver = os.getenv('STORAGE_DRIVER', 'local').lower() if driver == 's3': return S3StorageDriver() if driver == 'minio': return MinioStorageDriver() return LocalStorageDriver()
